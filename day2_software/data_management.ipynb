{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management for Individual Scientists\n",
    "\n",
    "Authors: Erik Tollerud & Brigitta Sip≈ëcz\n",
    "\n",
    "In Astronomy, \"Data Management\" is typically used to describe large-scale efforts like the Gigabytes-per-second Large Synoptic Survey Telescope or the over a hundred different observing modes James Webb Space Telescope.  But for an individual scientist, the general concept data management still applies, just in a very different sense: managing data from or for your own scientific projects.  This tutorial aims to suggest some guidelines and pitfalls for personal data management.\n",
    "\n",
    "While this tutorial covers several levels of complexity, there is one golden rule, which you should remember even if you remember nothing else: Do Not Make Your Own Format. You need only examine the examples that are shown in [the astropy table reader docs](http://docs.astropy.org/en/stable/io/ascii/#supported-formats) or the related [fixed width gallery](http://docs.astropy.org/en/stable/io/ascii/fixed_width_gallery.html#fixed-width-gallery) to see the needless complexity that has been introduced by well-meaning astronomers that chose to roll their own.  While the tools available to us often make it easy, do your best to resist. Future collaborators, future co-workers, future students, and future you will thank you.\n",
    "\n",
    "Note that while this tutorial is primarily based on Python and some parts are Python-specific to provide concrete examples, most of the guidelines discussed here apply to a range of approaches and languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM the Easy Way: \"automatic\" tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Caching\n",
    "\n",
    "Some software packages provide caching - i.e., after a file is downloaded, it's automatically saved somewhere and used automatically the next time you ask for it. This can be a convenient way to ensure data you need for your work is available and limit your impact on remote servers that might provide the data.\n",
    "\n",
    "As an example, consider the following function for downloading a Hubble Space Telescope image of one of the greatest galaxies - the Local Group dwarf GR8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils import data\n",
    "from astropy.io import fits\n",
    "\n",
    "gr8_url = 'https://archive.stsci.edu/pub/hlsp/angst/acs/hlsp_angst_hst_acs-wfc_10915-gr8_f814w_v1_ref.fits'\n",
    "gr8_fn = data.download_file(gr8_url, cache=True)\n",
    "fits.open(gr8_fn).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you run this it should take a little while to run the download (it's a 70MB file), but if you run it again, you'll see it's almost instantaneous.  This is because the file has been saved in a (relatively hidden to you) location and is re-used when you ask for it again.\n",
    "\n",
    "This may seem like an easy way to manage your data, but consider these cases:\n",
    "* What happens if the remote file gets udated?\n",
    "* What happens if you start running out of space and want to delete some of your old data files?\n",
    "\n",
    "You can address these manually by running the cell below, but consider what happens if you lose this notebook sometime between now and when the problems above arise. For this reason, this general problem has been enshrined in an computer science/software engineering adage: https://martinfowler.com/bliki/TwoHardThings.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.clear_download_cache(gr8_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see this problem a little more clearly, consider the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord, EarthLocation\n",
    "\n",
    "sc = SkyCoord(ra=1, dec=2, unit='deg',\n",
    "              frame='fk5', obstime='2019-8-1',\n",
    "              location=EarthLocation.of_site('kitt peak'))\n",
    "sc.transform_to('altaz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on when/if you've last used code like this, it might take a little while to run the first time, because behind the scenes the code has to look up the exact orientation of the Earth on the day in question (something that is not fully predictible due to things like earthquakes and therefore requires data downloads).  These data change regularly, so behind the scenes careful management is required by the software to ensure the file stays up to date and you aren't constantly served an out-of-date file that gives inaccurate position information, ruining your precision science.\n",
    "\n",
    "To sum up - while caching is a viable solution if the software you were using is careful about managing it for you, in general you should not rely on it unless you are sure the data are never going to change, are publicly available, and are small enough you don't have to worry about deleting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling\n",
    "\n",
    "Now lets consider the topic of *saving* data (as opposed to getting it). Python and its wider ecosystem provides a few ways of doing this that are built-in and relatively easy.  But as with caching, the easiest ways come with certain pitfalls.\n",
    "\n",
    "Consider the following generated image - how would we save it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "image_scaling_factor = 1e4\n",
    "xpix, ypix = np.mgrid[:512, :512]\n",
    "img = xpix * ypix + np.random.randn(512, 512) * image_scaling_factor\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides a built-in way to handle basic data like this, called \"pickling\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_to_save = {'image': img, 'xy': (xpix, ypix), 'image_scaling_factor': image_scaling_factor}\n",
    "with open('mydata.pickle', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mydata.pickle', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that you can save out the image and some extra information with a minimum of fuss, and load it again almost as simply. However, there are some serious drawbacks here - to start with, take a look at the size of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize('mydata.pickle')/1024/1024 # MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large do you expect? Why might this not be ideal, particularly if this were a significantly larger dataset?\n",
    "\n",
    "Moreover, `pickle` has some more subtle drawbacks. The following cells illustrate some of these.\n",
    "\n",
    "#### Pickle Issue 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_management.ipynb', 'r') as nb_file:\n",
    "    data_to_save = {'image': img, 'file_to_open': nb_file}\n",
    "    with open('mydata.pickle', 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is straightforward: not all types are picklable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Issue 2\n",
    "\n",
    "Let's say you've decided to use Python for it's object-oriented power.  You decide to make an image generator *class* instead of pickling the data itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator:\n",
    "    def __init__(self, imgsize, imgscl):\n",
    "        self.imgsize = imgsize\n",
    "        self.imgscl = imgscl\n",
    "        \n",
    "    def make_image(self):\n",
    "        xpix, ypix = np.mgrid[:self.imgsize[0], :self.imgsize[1]]\n",
    "        return xpix * ypix + np.random.randn(*xpix.shape) * self.imgscl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagegen = ImageGenerator((512, 512), 1e4)\n",
    "\n",
    "with open('mydata.pickle', 'wb') as f:\n",
    "    pickle.dump(imagegen, f)\n",
    "with open('mydata.pickle', 'rb') as f:\n",
    "    imagegen_loaded = pickle.load(f)\n",
    "    \n",
    "plt.imshow(imagegen_loaded.make_image());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good.  But now let's say you realize you want to re-work the class to use a more useful variable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator:\n",
    "    def __init__(self, image_size, image_scaling_factor):\n",
    "        self.image_size = image_size\n",
    "        self.image_scaling_factor = image_scaling_factor\n",
    "        \n",
    "    def make_image(self):\n",
    "        xpix, ypix = np.mgrid[:self.image_size[0], :self.image_size[1]]\n",
    "        return xpix * ypix + np.random.randn(*xpix.shape) * self.image_scaling_factor\n",
    "\n",
    "with open('mydata.pickle', 'rb') as f:\n",
    "    imagegen_loaded = pickle.load(f)\n",
    "    \n",
    "plt.imshow(imagegen_loaded.make_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the old object unpickled just fine... but doesn't work!  This is a simple example of a more general problem that if you ever need to re-name, re-design or otherwise change something you've pickled, and often renders all your pickles somewhere between mildly broken and completely unpickleable. And that's bad.\n",
    "\n",
    "#### Pickle Issue 3\n",
    "\n",
    "Now lets say you get an email \"from\" a trusted collaborator who includes a file for you to use.  You good naturedly load it up and see this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_is_a_very_safe_pickle_trust_me = b\"\\x80\\x03cbuiltins\\nexec\\nq\\x00X\\x8b\\x01\\x00\\x00\\nimport base64\\nexec(base64.b64decode(b'CnByaW50KCJJIENBTiBIQVogQ0hFRVNFQlVSR0VSLiBBbHNvIEkgaGFja2VkIHlvdXIgZGF0YS4iKQppZiAnaW1hZ2VnZW5fbG9hZGVkJyBpbiBnbG9iYWxzKCk6CiAgICBpbWFnZV90b19oYWNrID0gZ2xvYmFscygpWydpbWFnZWdlbl9sb2FkZWQnXQogICAgZm9yIGksIG5hbWUgaW4gZW51bWVyYXRlKGltYWdlX3RvX2hhY2suX19kaWN0X18pOgogICAgICAgIHNldGF0dHIoaW1hZ2VfdG9faGFjaywgbmFtZSwgJ/CfkIgnIGlmIGklMj09MCBlbHNlICfwn42UJykK'))\\nq\\x01\\x85q\\x02Rq\\x03.\"\n",
    "\n",
    "pickle.loads(this_is_a_very_safe_pickle_trust_me)\n",
    "    \n",
    "imagegen_loaded.imgsize, imagegen_loaded.imgscl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this demonstrates, pickle is an inherently insafe format because it has the potential to execute any arbitrary code while being unpickled (to see how this was done, you can look at `safe.py` in this repo). That means you should never trust any pickle someone sends you... So it's effectively useless for sharing data with others. \n",
    "\n",
    "#### Pickle Issue 4\n",
    "\n",
    "On top of all that, the pickle format *itself* changes over time, such that pickles produced by a newer Python may not work on older versions of Python, and essentially none of them work with any language other than Python.\n",
    "\n",
    "Taken together, that means pickle, while very convenient, is not useful for anything beyond saving your *own* data if it's either very simple data, or something that you're sure won't ever change (and trust me... it will)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: the numpy formats\n",
    "\n",
    "Similar, but somewhat different from the pickle format are the `npy` and `npz` formats.  These are files that the `numpy` package can produce from `numpy` arrays.  While they provide a similar quick-and-easy way to save out data from Python, they also have their own drawbacks (some similar to Pickle, others less so).  Explore trying to replicate the pickle example but with the `numpy` formats, and compare and contrast the advantages/disadvantages.  Discuss with your neighbor if you are both willing and interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DM the slightly harder way: managing files \n",
    "\n",
    "While the above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables/catalogs\n",
    "\n",
    "1. demo csv-writers\n",
    "2. show the dangers of non-roundtripping (demoing ECSV as an example of keeping metadaya)\n",
    "3. compare csv to fits - binary better, but row-based\n",
    "4. Do a row/column-major comparison - asdf? or hdf5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images/data files\n",
    "\n",
    "1. show how fits and hdf5 are both reasonable as raw images\n",
    "2. demo data structures like nddata\n",
    "3. demo file *management* using https://ccdproc.readthedocs.io/en/latest/image_management.html as a case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Real DM\": databases\n",
    "\n",
    "1. show how shelve can do in a pinch, but \n",
    "2. describe sqlite and show an example of using it locally to store data\n",
    "3. link to aq tutorial (Gaia or sdss - whichever is query)\n",
    "\n",
    "\n",
    "Mention spark/AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
